{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cca882e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming download from 32995540992 bytes (12100609239 bytes left)...\n",
      "Resuming download from https://www.kaggle.com/api/v1/datasets/download/nih-chest-xrays/data?dataset_version_number=3 (32995540992/45096150231) bytes left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 42.0G/42.0G [06:11<00:00, 32.6MB/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/pedrosof/.cache/kagglehub/datasets/nih-chest-xrays/data/versions/3\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"nih-chest-xrays/data\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a8e2bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens encontradas: 112120\n",
      "Dataset reduzido em: /Users/pedrosof/Documents/FIAP/Trabalhos/TIAOR_2/CardioAI--Fase4/chest_xray\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Diretório original baixado pelo kagglehub\n",
    "original_dir = path\n",
    "\n",
    "# Novo dataset reduzido\n",
    "dataset_dir = \"/Users/pedrosof/Documents/FIAP/Trabalhos/TIAOR_2/CardioAI--Fase4/chest_xray\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "splits = [\"train\", \"val\", \"test\"]\n",
    "classes = [\"NORMAL\", \"ANOMALY\"]\n",
    "\n",
    "for split in splits:\n",
    "    for cls in classes:\n",
    "        os.makedirs(os.path.join(dataset_dir, split, cls), exist_ok=True)\n",
    "\n",
    "# Listar alguns arquivos (DICOM/JPG/PNG)\n",
    "all_images = []\n",
    "for root, dirs, files in os.walk(original_dir):\n",
    "    for f in files:\n",
    "        if f.lower().endswith((\"png\", \"jpg\", \"jpeg\")):\n",
    "            all_images.append(os.path.join(root, f))\n",
    "\n",
    "print(\"Total de imagens encontradas:\", len(all_images))\n",
    "\n",
    "# Selecionar subconjunto (ex.: 300 imagens)\n",
    "SAMPLES = 300\n",
    "subset = random.sample(all_images, SAMPLES)\n",
    "\n",
    "# Divisão 70/15/15\n",
    "train_split = int(0.7 * SAMPLES)\n",
    "val_split = int(0.15 * SAMPLES)\n",
    "test_split = SAMPLES - train_split - val_split\n",
    "\n",
    "train_files = subset[:train_split]\n",
    "val_files = subset[train_split:train_split+val_split]\n",
    "test_files = subset[train_split+val_split:]\n",
    "\n",
    "def copy_files(file_list, split_name):\n",
    "    for f in file_list:\n",
    "        cls = random.choice(classes)  # Como não há labels no NIH, classificamos artificialmente\n",
    "        dest = os.path.join(dataset_dir, split_name, cls, os.path.basename(f))\n",
    "        shutil.copy(f, dest)\n",
    "\n",
    "copy_files(train_files, \"train\")\n",
    "copy_files(val_files, \"val\")\n",
    "copy_files(test_files, \"test\")\n",
    "\n",
    "print(\"Dataset reduzido em:\", dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea5e25df",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os # Importar os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 1. Redução do tamanho da imagem para economizar RAM\n",
    "IMG_HEIGHT = 150 \n",
    "IMG_WIDTH = 150\n",
    "BATCH_SIZE = 8 # Mantido em 8\n",
    "\n",
    "# Assumindo que dataset_dir foi definido em uma célula anterior\n",
    "# Exemplo: dataset_dir = \"/Users/pedrosof/Documents/FIAP/Trabalhos/TIAOR_2/CardioAI--Fase4\" \n",
    "\n",
    "train_dir = os.path.join(dataset_dir, \"train\")\n",
    "val_dir   = os.path.join(dataset_dir, \"val\")\n",
    "test_dir  = os.path.join(dataset_dir, \"test\")\n",
    "\n",
    "# 2. Simplificar o datagen temporariamente, ou manter o seu, com atenção ao ponto 3.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    zoom_range=0.05,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 3. Adicionar color_mode se as imagens forem P&B (Comum em Raio-X)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir, \n",
    "    target_size=(IMG_HEIGHT,IMG_WIDTH), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    class_mode='binary',\n",
    "    color_mode='grayscale' # Use 'grayscale' se forem P&B\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir, \n",
    "    target_size=(IMG_HEIGHT,IMG_WIDTH), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    class_mode='binary', \n",
    "    shuffle=False,\n",
    "    color_mode='grayscale' # Use 'grayscale' se forem P&B\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir, \n",
    "    target_size=(IMG_HEIGHT,IMG_WIDTH), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    class_mode='binary', \n",
    "    shuffle=False,\n",
    "    color_mode='grayscale' # Use 'grayscale' se forem P&B\n",
    ")\n",
    "\n",
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa915983",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(x_batch[i])\n",
    "    plt.title(f\"Classe: {int(y_batch[i])}\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5409b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Visualizar algumas imagens pós-pré-processamento (apenas para conferência)\n",
    "x_batch, y_batch = next(train_generator)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_batch[i])\n",
    "    plt.title(f\"Classe: {int(y_batch[i])}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e75ab55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import dedent\n",
    "\n",
    "print(dedent(f\"\"\"\n",
    "Pipeline de Pré-processamento – CardioAI Fase 4\n",
    "\n",
    "1. Download automático:\n",
    "   - Dataset NIH Chest X-Ray baixado via kagglehub.\n",
    "   - Evita dependências com Google Drive ou composições manuais.\n",
    "\n",
    "2. Tratamento inicial:\n",
    "   - Dataset NIH tem 112.000+ imagens sem classes organizadas.\n",
    "   - Criado subconjunto reduzido de {SAMPLES} imagens para execução rápida no Colab.\n",
    "\n",
    "3. Organização artificial das classes:\n",
    "   - Como o dataset NIH não tem rotulagem direta, as classes NORMAL e ANOMALY são atribuídas aleatoriamente apenas para fins educacionais.\n",
    "   - Simula um cenário real de classificação binária.\n",
    "\n",
    "4. Pré-processamento:\n",
    "   - Redimensionamento para 224x224 (compatível com CNNs e modelos pré-treinados).\n",
    "   - Normalização em 0–1.\n",
    "   - Data augmentation leve no treino (rotação, zoom, flip).\n",
    "   - Conjuntos train/val/test criados na proporção 70/15/15.\n",
    "\n",
    "5. Justificativas:\n",
    "   - kagglehub simplifica e centraliza o acesso ao dataset.\n",
    "   - Subset reduzido viabiliza treinamento rápido.\n",
    "   - Padronização prepara o pipeline para a Parte 2 (CNN e Transfer Learning).\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cadef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CardioAI - Fase 4 - Parte 2: CNN + Transfer Learning\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "BATCH_SIZE = 32\n",
    "train_generator = None  # substitua carregando o gerador do notebook anterior\n",
    "val_generator = None\n",
    "test_generator = None\n",
    "\n",
    "def create_simple_cnn(input_shape=(224,224,3)):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# exemplo (comente se não tiver os generators carregados)\n",
    "# model = create_simple_cnn()\n",
    "# model.fit(train_generator, validation_data=val_generator, epochs=5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
